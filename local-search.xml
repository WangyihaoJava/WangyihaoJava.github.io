<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>rocketMQ常见问题以及原理</title>
    <link href="/2021/08/05/rocketMQ%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86/"/>
    <url>/2021/08/05/rocketMQ%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>消息存盘速度</p><p>如果磁盘用的合理 磁盘的速度完全匹配网络传输速度目前的高性能磁盘，顺序写速度</p><p>可以达到600MB/s 但是随机读写只有100k/s rocketmq采用的是顺序读写</p><p>另外使用的零拷贝中mmap技术实现减少用户态的切换</p><p>存储结构主要有三块</p><p>CommitLog 消息存储</p><p>ConsumerQueue 消息消费到哪的索引</p><p>IndexFile 提供一些根据key或者时间区查询的方式</p><p>abort 文件在启动时候创建正常关闭时候删除 如果非正常关闭不会删除 可以通过这个文件来判断是否正常</p><p>刷盘 </p><p>同步 安全不会产生丢消息 会影响性能</p><p>异步 性能比较高 可能会丢消息</p><p>主从复制</p><p>同步</p><p>异步</p><p>负载均衡</p><p>生产者会轮询目标下topic所有MessageQueue</p><p>也可以指定MessageQueue往一个里面发消息</p><p>也可以平均分配到各个MessageQueue</p><p>也可以设置同机房优先分配</p><p>重试消息 </p><p>如果消费失败可以进行重试 如果一直失败 超过16次会进入到死信队列</p><p>死信队列</p><p>需要人工处理</p><p>消费幂等</p><p>在互联网尤其是网络不稳定情况容易出现</p><p>发送时消息重复</p><p>投递时消息重复</p><p>负载均衡时消息重复</p><p>rocketmq保证分布式事务</p><p>首先生产者在生产消息前会向mq发一个half消息 mq收到消息后会响应一个half这样保证mq没有宕机</p><p>然后生产者执行本地事务 正常提交或者回滚都会发到mq 正常的就正常消费 回滚的就丢弃</p><p>因为提交本地事务有可能时间比较长 mq 也不会一直等 如果超过时间后 mq定期回查本地事务状态</p><p>生产者收到回查请求后会进行回查本地事务状态 然后将状态进行提交到mq</p><p>Dledger保证集群高可用</p><p>在rocketmq4.5之前是不能保证高可用的 在这个版本之后引入Dledger保证集群的高可用</p><p>它会接管commitlog消息存储</p><p>每个节点有三个状态，Leader，follower和candidate 初始状态大家都是follower 集群内部会有一个超市信号</p><p>大家都变成candidate 向其他成员发送请求 获得票数最多的就会成为leader 没有选出就会再次选举</p><p>Leader 会定期往follower发送心跳保证自己的地位 如果follower长时间没有收到心跳就会转为candidate向其他节点发送请求 超过半数就会成为leader</p><p>在raft协议中有一个逻辑时钟的概念叫做term</p><p>也就是每到这term时间会进行重新选举 选举成功的节点会保持一个leader的状态 这也就保证了在同一时间内只会有一个leader 不会产生脑裂的问题</p><p>两阶段提交</p><p>leader收到数据后会将数据标为uncommitted 然后将数据同步给从节点 从节点接收完数据后会返回给leader一个ack 当超过一半的从节点都返回了ack leader会将这个数据状态改为commited</p><p>这样就保证了如果宕机重启发现这个标识会进行重新同步</p><p>rocketmq如何保证不重复消费</p><p>在RocketMQ中，是无法保证每个消息只被投递一次的，所以要在业务上</p><p>自行来保证消息消费的幂等性。</p><p>而要处理这个问题，RocketMQ的每条消息都有一个唯一的MessageId，这个参数在多次投递的过程中</p><p>是不会改变的，所以业务上可以用这个MessageId来作为判断幂等的关键依据。</p><p>但是，这个MessageId是无法保证全局唯一的，也会有冲突的情况。所以在一些对幂等性要求严格的场</p><p>景，最好是使用业务上唯一的一个标识比较靠谱。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>mysql之索引和事务的原理</title>
    <link href="/2021/08/03/mysql%E4%B9%8B%E7%B4%A2%E5%BC%95%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%8E%9F%E7%90%86/"/>
    <url>/2021/08/03/mysql%E4%B9%8B%E7%B4%A2%E5%BC%95%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>索引篇<br>为什么不用二叉树 因为他的树的深度会越来越高 如果如果往一边倒</p><p>红黑树也是一样虽然他会自动平衡 但是在海量数据下他的树高度还是很高</p><p>b树就是为了解决树的高度 横向放的元素越多 树的高度越低 存储的数据越多</p><p><img src="C:\Users\Administrator\Desktop\暂存图片\截图.png" alt="截图"></p><p>B+树是b树的变种 非叶子结点冗余索引 为了存储更多的数据</p><p>从左到右依次递增排序</p><p>​    <img src="C:\Users\Administrator\Desktop\暂存图片\截图.png" alt="截图"></p><p>B+树是怎么查找数据的 首先先把根节点加载到内存中通过类似二分查找定位大概在哪个区间找到对应叶的磁盘文件地址 然后再往下重复加载查找直到找到数据</p><p>一个节点是16k能存1170个索引 也就是树的高度是3能存1170<em>1170</em>16是两千多万</p><p>根叶子节点可能常驻内存</p><p><img src="C:\Users\Administrator\Desktop\暂存图片\截图.png" alt="截图"></p><p>索引和数据分开存储叫非聚簇索引 存在一起叫聚簇索引 myisam最后的叶子结点存的是数据的文件地址 需要通过文件地址去指定的文件里面拿数据</p><p>innodb只有主键索引是聚簇索引 二级索引都是非聚簇索引 他的叶子节点存的是主键索引的文件地址 都需要进行回表来获取数据</p><p>为什么建议innodb必须主键</p><p>因为如果没有主键musql底层无法维护一个b+树 要么从表里面找一列不重复的作为索引 要么自己建一个隐藏列</p><p>‘为什么推荐整形自增主键</p><p>找一个元素是从根结点 找元素其实就是逐个比大小 如果是字符串还要把字符串专程ascii码再进行比对效率低</p><p>自增是因为会影响b+树叶子节点的结构的平衡 他会自己再进行重平衡影响性能</p><p>hash是利用hash算法去定位某个元素 在很大程度上一次就可以定位到元素的位置 但是hash不能做等值查找 也不能做范围查找 因为b+树他的叶子节点是一个双向链表可以通过一个叶子快速定位到下一个叶子 按照这种方式快速锁定一个范围 然后这个范围的数据加载出来就拿到了数据</p><p>​    <img src="C:\Users\Administrator\Desktop\暂存图片\截图.png" alt="截图"></p><p>最左前缀就是当一个联合索引会先根据最左边的进行排序，然后再第一个字段排序的基础上对第二个字段进行排序，以此类推，只有再第一个字段相同的情况下第二个字段才是有序的，如果无序就会走全扫描索引，索引再创建联合索引的时候尽量将用到范围的字段放在后面，不然会导致全扫描索引</p><p>索引下推是在</p><p>最左前缀为什么这样做的 要从左到右使用索引</p><p>因为它底层会根结联合索引进行排序，联合索引是根据这些索引字段从左到右依次进行排序， 如果没有最左边的字段 无法确认后面字段的顺序，只有最左边相同后面一个才是排好序，无法确定它的顺序就只能通过全表扫描</p><p>​                </p><p>什么是索引下推了?</p><p>对于联合索引 正常情况下按照对做匹配原则，比如三个字段的联合索引 第一个字段用到了右模糊 因为扎样查到的数据就是无序的了 第二和第三无法使用到索引 mysql5.6之前会将过滤出来的索引对饮的主键逐个进行回表查询 再对比后面两个字段的值是否符合 MySQL 5.6引入了索引下推优化，可以在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可以有效的减少回表次数。使用了索引下推优化后，在过滤完第一个字段的左模糊后还会再过滤后面两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。                     </p><p>索引下推会减少回表次数，对于innodb引擎的表索引下推只能用于二级索引，innodb的主键索引(聚簇索引)树叶子节点上保存的是全 行数据，所以这个时候索引下推并不会起到减少查询全行数据的效果。         </p><p>覆盖索引 二级索引里面有当前索引的值和主键索引的值 走覆盖索引就是 只查询主键和当前索引的值 不会回表</p><p>范围查找age &lt; 10  age &gt;1 后面的&gt;不会走索引 联合索引中有范围的字段最好建在后面</p><p>如果最后字段的前面字段不用 为了走索引可以直接冗余写死 为了走索引</p><p>那么如果联合索引中有两个范围查找 肯定不会走索引 比如年龄和最近七天登陆</p><p>可以想办法把七天登陆换成一个标识 0 1 0没有登陆 1登陆减少一个范围字段</p><p>如果实在不行就再建一个联合索引 一个表里面可以建2-3个联合索引 如果建的太多会影响插入 删除 因为他要维护那个索引树 </p><p>where和order by冲突的话优选满足where因为用where过滤之后一般数量都是比较小的 就算order by不走索引使用文件排序也没关系</p><p>事务篇<br>可重复度读其实不是使用的mvcc机制来控制并发，而串行化是通过加锁来解决并发，在读的时候都加一个锁，由于是用的mvcc机制当我们操作这个隔离级别的事务的时候底层数据有可能会在变化的，所以我们在操作更新的时候update400 - 50 = 350）如果涉及再次更新 不要用（350这个数据 而要用数据库实时数据 也就是再查一次</p><p>另外串行化加锁是针对某条数据，比如说加一个数据有一个1了，在加ID是6的数据，在提交之前是可以查到1的，但是要是查6就会一直阻塞，直到那边提交6的数据</p><p>可重复读不能解决幻读 间隙锁可以解决幻读 他其实就是把所有的间隙锁住 无法新增了 就不会有幻读现象了 幻读就是当开启一个事物的时候 别的事物提交了一个新增数据 第一条事物还能读取到</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Spring-IOC+AOP</title>
    <link href="/2021/07/29/Spring-IOC+AOP/"/>
    <url>/2021/07/29/Spring-IOC+AOP/</url>
    
    <content type="html"><![CDATA[<p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210806163141604.png" alt="image-20210806163141604"></p><p>beanfactory就是一个顶层的类用来创建bean</p><p>factorybean是一个接口 实现它的类就是一个特殊的类 最终去调用他的重写的方面getobject返回的bean</p><p>@configuration加与不加的区别 比如一个bean里面有个属性是一个对象 加的话会从容器里面通过getbean拿这个对象 保证这个对象是单例的 不加话配置类里面bean和bean之间引用就是普通的调用 每次创建一个对象 不受ioc容器控制</p><p>beanname覆盖</p><p>如果@compont是通过scan扫描的如果扫描出来两个名字一样的类 会报错</p><p>但是如果@compont和@bean中两个名字一样的类 @bean会把前者覆盖 因为@bean是后执行的是在getbean之后解析成bean定义的 前者是在getbean之前进行解析成bean定义的</p><p>三级缓存</p><p>一级缓存解决循环依赖会有多线程情况下获取到不完整的bean</p><p>二级缓存出现解决了这个问题 将成熟bean和纯净bean分离 成熟的bean放进一级缓存 纯净bean二级缓存</p><p>为什么还要三级缓存 spring是想如果没有循环依赖的ban还是在初始化之后通过beanpostprocessor进行创建动态代理这样也符合单一职责 接耦 所以它使用了一个钩子函证钩子函数就是beanpostprocessor里面进行创建动态代理 用刚刚在put二级缓存的时候换成使用这个方法解决aop循环依赖问题 其实使用二级缓存同样也可以解决aop循环依赖 只不过spring这样实现更加规范</p><p>spring为什么没有解决构造循环依赖</p><p>因为构造函数还在实例化中 没有实例化完根本拿不到这个bean 不存在解决循环依赖</p><p>spring为什么没有解决多例循环依赖</p><p>因为多例没有放到缓存里面去 如果多例有循环依赖直接抛异常</p><p>AOP</p><p>前置通知后置通知都是通过责任链方式调用</p><p>责任链必须要有一个统一的抽象 这样他们才能依次调用 要么用循环调用要么用递归</p><p>aop实现流程主要分为三大步</p><p>解析切面</p><p>在第一个beanpostprocessor后置处理器里面扫描所有带@aspactj注解的类 将类里面的@before等注解生成一个advisor advisor包含advise和pointcut</p><p>创建动态代理</p><p>初始化之后创建动态代理</p><p>会进行初始化</p><p>拿到刚刚解析的所有的advisor跟当前正在创建的bean进行匹配(怎么匹配就是调用aspectj里面的api先做粗筛再做精筛)匹配完成后会加到一个list里面去 如果list里面有说明满足条件 为当前正在创建的bean生成一个动态代理 有实现接口实现就使用jdk动态代理 没有就用cjlib动态代理 </p><p>调用代理</p><p>将advisor转换成intercepter 在intercepter 进行递归责任链</p><p>aop的调用代理与事务的调用代理不一样 aop是我们自定义的@before 而事务是内置的</p><p>aop有几种实现方式</p><p>基于接口 就是spring最初的方式</p><p>基于注解 就是后来升级的方式</p><p>基于xml</p><p>在本类里面如果是jdk动态代理调用本类里面的方法不会执行动态代理的方法，因为jdk使用的是反射每次都会生成.class然后都直接调用方法，</p><p>这也就是为什么事务在同一个类里面调用会失效的原因了，它不会对同一个类里面的方法进行重复增强。</p><p>jdk动态代理只会生成一个.class文件 </p><p>而cjlib会生成多个.class文件 调用动态代理每次会路由找到cjlib动态代理类 再次调用还会来到这个路由 这就是在一个类里面多次调用只会生成一个动态代理类的原因 cjlib在本类能重复增强的原因就是他是通过继承的方式 直接调用实现了被代理类的子类（动态代理类）可以作为@config加与不加区别中扩展</p><p>jdk和cjlib</p><p>cjlib石通过给每一个方法创建一个动态代理对象 会对每个方法生成一个hashcode索引也可以称为路由 每次调用的时候通过这个路由获取动态代理对象 </p><p> jdk是通过反射的方式</p><p>jdk是自己生成的字节码文件 而cglib是通过asm生成多个字节码文件 启动时候可能cglib 略慢</p><p>代理原理区别</p><p>jdk会传入一个实例对象就是目标对象 然后通过对实例对象的反射实现增强</p><p>cglib通过继承的方式 会先将方法进行hashcode然后再回来去调用这个方法 去执行父类的方法就是增强类的方法</p><p>通过继承的方式就是 继承被代理的类 此时被代理类就是父类 增强的类就是子类 通过动态代理调用父类的select方法 他调用insert方法又会跑到子类的insert方法这就实现了重复拿到增强类也就是子类的方法 这就是本类调用会重复增强的原因</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>synchronized</title>
    <link href="/2021/07/16/synchronized/"/>
    <url>/2021/07/16/synchronized/</url>
    
    <content type="html"><![CDATA[<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><p>如果一个对象在方法中创建 没有被外部引用 在方法的结束该对象也就处于没有指向的状态 完全可以把它在栈空间创建 随着方法的结束而销毁<br>(逃逸分析)</p><p>是建立在逃逸分析的基础上 去除不可能存在竞争的锁<br>(锁消除)</p><p>相同的代码块经过多次加锁 在不影响执行结果的基础上 可以将这些代码放在同一个同步块里面 减少锁的开销<br>(锁粗化)</p><p>锁升级 是单向的不可逆</p><p>无锁</p><p>偏向锁</p><p>markwod锁标记且00 多个线程交替执行升级轻量级锁</p><p>自旋锁</p><p>重量级锁</p><p>markwod锁标记且01 是否偏向为0<br>(无锁)</p><p>markwod锁标记且01 是否偏向为1 当只有一个线程的时候会升级成这种状态 jvm启动的时候会延迟偏向锁<br>(偏向锁)</p><p>轻量级锁失败后 为了避免线程被挂起 会进行自旋优化 因为大多数线程持有锁的时候不会太长 如果现在直接把线程挂起会经历从用户态切换到内核态 操作比较重 消耗时间比较长 其实自旋就是空循环<br>(自旋锁)</p><p>对象内存布局</p><p>对象头 8个字节 64bit</p><p>markword</p><p>metadata</p><h2 id="数组长度"><a href="#数组长度" class="headerlink" title="数组长度"></a>数组长度</h2><p>markword主要存放对象年龄  线程id 锁标志 是否偏向 epoch 等数据 32位和64位操作系统分别占 32bit和64bit  不过64位也会开启指针压缩到32bit</p><p>实例数据</p><h2 id="对齐填充数据"><a href="#对齐填充数据" class="headerlink" title="对齐填充数据"></a>对齐填充数据</h2><p>由于虚拟机要求 对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐；</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>主要有三种：加在静态方法或者成员方法上锁的当前方法，锁加在当前的类对象的对象头上，如果在方法里面的同步块里面锁的是当前同步块里面的内容，有三种方式object object.class this 三种方式都能实现代码的同步 区别在于粒度不同，应用场景不同可以选择不同的方式  this是把锁标识加在当前类上面粒度比较大 而object可以指定一个类    另外 注意在方法中禁止在多个静态方法中加synchronized 因为他们都是加在同一个类上面 也就是当前类 调用该方法时候qps会受到严重影响 因为调用两个方法需要先获取锁 如果第一个方法没有释放锁 调用第二个会一直阻塞  最后禁止在方法里面使用大量sout 因为里面也是用到了synchronized</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>synchronized底层基于jvm的内置锁 通过monitor来实现的 简单来说就是当加了 synchronized关键字之后 编译生成字节码后会翻译成monitorenter和monitorexit 这两条指令会在需要同步的代码块的起止位置     如果加了synchronized字符串常量池中会多ACC_SYNCHRONIZED jvm就是根据这个标识来判断是否有加锁 如果有这标识 会先获取monitor</p><h2 id="monitor"><a href="#monitor" class="headerlink" title="monitor"></a>monitor</h2><p>为什么要获取monitor 因为monitor是当每个对象创建的使用会一起被创建 类似一个监视器 当获取这个对象的monitor时该对象会处于锁定状态 jvm就是通过进入和退出monitor来实现加锁和解锁的操作  比如说线程a进入monitor 进入数会加1如果a再次进入这个进入数还会加1 如果b想要进入的话只能阻塞 直到进入数为0的时候才能进入</p><h2 id="MESI"><a href="#MESI" class="headerlink" title="MESI"></a>MESI</h2><p>当一个cpu从内存中读取数据的时候会将当前缓存行中的状态改为E独占，当另外一个cpu也去读取这个数据的时候，第一个cpu会检测到地址冲突，为了解决这个问题两个cpu都会将缓存行改为S共享状态         修改时会将要修改的值设置为M修改状态 并且通知其他缓存了该值的cpu 并把数据写入到内存   其他cpu接收到通知后把自己的数据改为I无效状态 重新到内存里面读取      注意这里修改完数据不是立即写入内存的 而是把修改的数据缓存到一个storebuffer里面 因为传递消息是需要时间的 这样可以提升效率</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>jvm内存模型总结</title>
    <link href="/2021/07/09/jvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/"/>
    <url>/2021/07/09/jvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210709110547362.png" alt="image-20210709110547362"></p><p>首先java代码通过编译器编译成class字节码文件，通过类加载系统经过 加载–&gt;验证–&gt;准备–&gt;解析–初始化等一系列操作加载到方法区，当然解析的过程会针对静态的方法替换为指向内存(数据所存内存指针，句柄等)的直接引用，另外动态链接是在方法运行时将符号引用替换为内存引用</p><p>方法区和堆会双向引用，因为堆里面存的是创建的对象，对象头也在这里，对象头有指针，指针指向的方法区中的类元数据，当然如果创建一个静态的对象，方法区中的内存地址会指向堆中该对象</p><p><strong>栈空间</strong>：每个线程会有自己的栈空间是独有的，可以把每个栈由各种栈帧组成，每个方法代表一个栈帧，每个栈空间默认是1m，当然也可以通过参数-Xss设置栈大小，设置的越小可以创建的线程越多，当然可以存放的栈帧就越少，具体需要根据业务需要进行设置</p><p>程序计数器：记录 程序执行到哪个位置，代码最终在底层会转为字节码，就是记录字节码的行号</p><p>本地方法栈：很多被native修饰的方法是c++实现的本地方法，所以如果调用这些方法也需要栈空间，当然也是私有的</p><p>每个栈帧包含以下内容</p><p>局部变量表：主要存储变量值，对象的内存地址</p><p>操作数栈：存储临时变量值，对临时变量值进行运算</p><p>动态链接：因为编译后的class文件，底层是由各种符号引用实现的，这里就是把符号引用转为直接引用</p><p>方法出口：每个方法执行结束后要知道当前栈帧的位置，方法出口就是记录当前执行到哪个位置</p><p>堆空间：当eden区满了之后会触发minorgc，将eden区存活的对象放进s0区，存活的对象年龄加一，第二次满了后会同时清理eden和s0区，将存活的对象放进s1区，这样周而复始，当年龄达到15岁之后会挪到老年代，为什么是15岁，因为对象的年龄是存储在对象头中，分配了4个bit位最大只能存储15。</p><p>什么样的对象会直接进入老年代，大对象，如果往s区挪动的时候，存活这批对象大小大于s区的一半，就会将s区中大于这批对象中最大年龄的对象放进老年代。</p><p>逃逸分析：就是分析对象的作用范围，如果只是在一个方法中定义，没有被方法以外所引用，随着方法的结束这个对象就是无效的对象了，那么就可以给这个对象分配在栈内存，随着方法的结束被回收掉</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>23种设计模式-代理模式-动态代理</title>
    <link href="/2021/06/30/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"/>
    <url>/2021/06/30/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>代理模式</p><p>比如Source需要实现一个方法的增强，但是不能在a源码上面直接修改，因为Source被其他引用了，不符合开闭原则(对修改关闭，对增加开放)。</p><p>此时可以通过一个代理对象Invoke，实现Source的相同功能，构造方法中传入Source，在这个相同的功能上面做方法增强。</p><p>这时创建一个代理对象Invoke传入Source就可以实现方法的增强，并且没有修改源文件</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210630104610608.png" alt="image-20210630104610608"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210630104610608.png" alt="img"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210630104655327.png" alt="image-20210630104655327"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210630104804105.png" alt="image-20210630104804105"></p><p>动态代理</p><p>不可能为每个需要增强方法的类都创建一个代理对象，动态代理就解决了这种问题，其核心问题增强的方法是一定的，怎么让代理对象动态的获取被代理对象要执行的方法，其实是代理对象在初始化的时候利用了反射，获取了被代理对象的classloader和interface，这样代理对象就可以实现被代理对象的原方法加上自己的增强方法实现动态代理</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210630104818777.png" alt="image-20210630104818777"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210630104717387.png" alt="image-20210630104717387"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>redis总结</title>
    <link href="/2021/06/30/redis%E6%80%BB%E7%BB%93/"/>
    <url>/2021/06/30/redis%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p>​                                                                                                  </p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210629164922376.png" alt="image-20210629164922376"></p><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><p>string</p><p>应用场景<br>分布式全局序列号<br>INCRBY  orderId  1000  redis批量生成序列号提升性能<br>每台每次拿1000,0<del>1000,1001</del>2000,2001~3000<br>拿完后再各自慢慢处理这1000的容量<br>计数器</p><p>hash</p><p>就是一个双层map<br>key中一个value，value中还是一个map<br>使用场景需要将一个对象的属性拆分存入redis中<br>优点<br>1）同类数据归类整合储存，方便数据管理<br>2）相比string操作消耗内存与cpu更小<br>3）相比string储存更节省空间</p><p>缺点<br>过期功能不能使用在field上，只能用在key上<br>Redis集群架构下不适合大规模使用<br>因为如果一个hash的key中的属性很多的话，只能存在一个redis节点上，那么这个节点压力会比其他节点压力大很多，造成redis集群下压力分配不均衡！</p><p>list</p><p>模拟分布式系统数据结构<br>①：Stack(栈) = LPUSH（左边放） + LPOP（左边取）<br>②：Queue(队列）= LPUSH（左边放） + RPOP（右边取）<br>③：Blocking MQ(阻塞队列）= LPUSH（左边放） + BRPOP（右边阻塞取：没有数据就阻塞！）</p><p>问：那么redis实现的数据结构和jdk中提供的数据结构有什么区别呢？<br>答：jdk提供的数据结构仅在本服务中有用，如果在分布式环境下，则需要借助redis等中间件，模拟数据结构来统一管理数据</p><p>set</p><p>set1：（a、b、c）<br>set2：（b、c、d）<br>set3：（c、d、e）</p><h5 id="关注模型"><a href="#关注模型" class="headerlink" title="关注模型"></a>关注模型</h5><p>三个集合的<br>交集为：SINTER set1 set2 set3 ==&gt; { c }<br>并集为：SUNION set1 set2 set3 ==&gt; { a,b,c,d,e }<br>差集为：SDIFF set1 set2 set3 ==&gt; { a }<br>差集计算方式：set1 - （set2并set3） = {a、b、c} - {b、c、d、e} = {a} 只保留a中单独存在的元素</p><p>共同关注A的人：可以用交集来实现<br>我可能认识的人：可以使用差集来实现，把我关注的人求差集<br>我关注的人也关注A：可以使用SISMEMBER 命令查看A是否在我关注的人的关注列表中，如果存在把这个人返回</p><p>zset</p><p>zset相比于set多一个score 分值，正是根据这个分值进行排序，所以zset才能展示有序的数据</p><h5 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h5><p>rdb</p><p>rdb快照就是可以根据配置save 多长时间 多少个key被修改过执行一次快照，以二进制流的方式将当前数据保存到dump.rdb中<br>每次命令执行都会将所有redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。</p><p>有两种写入模式save和bgsave<br>save是同步进行，会阻塞客户端执行命令</p><p>bgsave是redis借助操作系统提供的写时复制技术（Copy-On-Write, COW）类似开启一个子线程来执行写入，如果在写入的这段时间主线程有有了新的修改数据，会存放在一个缓存副本里面，最后子线程执行副本里面的数据写入rdb文件<br>但是bgsave会消耗内存，因为新开了一个子线程</p><p>配置自动生成rdb文件后台使用的是bgsave方式。</p><p>aof</p><p>因为rdb会造成最近数据丢失，如果宕机会造成这样情况，所以aop是每秒(可以设置每次还是每秒还是系统默认)将修改的命令保存到aof文件中，需要恢复时执行aof，但是这样会造成很多无效命令，redis会定期将内存中最新的数据写入到aof文件中，AOF重写redis会fork出一个子进程去做(与bgsave命令类似)，不会对redis正常命令处理有太多 影响</p><p>Redis 4.0 混合持久化  在重启的的时候一般会采用aof来恢复数据，因为数据比较全，但是相比rdb恢复速度比较慢，要解决这个问题aof在重写的时候不会直接将内存数据转成RESP命令写入aof文件，而是将重写这一刻之前的内训做rdb快照处理，并且将rdb快照数据和增量更新数据分别存在一起等重新完成后才会把原aof覆盖<br>所以在重启的时候可以先加载rdb内容，在重放增加aof文件</p><p>哨兵</p><p>哨兵是redis的一种特殊服务，不会提供读写，只监控主从节点的状态，当客户端第一次请求会通过哨兵找到主节点，后续就会直接访问主节点，当节点信息发生变化时哨兵会第一时间感知到，并将主节点通知给客户端</p><p>主从原理</p><p>当给主节点配置一个从节点后，不管是不是第一次连接，从节点会向主节点发送一个sync请求，这时主节点就会生成一个新的rdb通过bgsave方式发给从节点，此时主节点会继续正常工作，如果有新的修改会生成一个缓存，最后发给从节点，从节点收到rdb和缓存后，会先清理之前的数据，然后直接执行就行，如果有大量请求，主节点也不会每次都生成rdb，只持久化一次，最后主节点通过socket长连接将又来的新命令持续发给从节点保证数据一致性</p><p>集群和原理</p><p>如果用哨兵模式实现集群不仅操作比较繁琐，而且性能也不是很好，所以现在  采用集群的模式，会把各个节点分成每个小集群组，将所有数据分为16384槽位，每个节点负责一部分槽位，客户端请求时候也会把槽位配置信息返回给客户端，客户端缓存这一份信息，如果想查询某个key时就可以很快定位到在哪个小集群上，当然这份信息有改动同步机制。<br>如果客户端发出一个错误命令，小集群发现该指令不归自己管，就会返回正确的地址，客户端重新向正确的地址操作</p><p>每个节点都有一个专门用于节点间gossip通信的端口，就是自己提供服务的端口号+10000，比如7001，那么  用于节点间通信的就是17001端口。 每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几  点接收到ping消息之后返回pong消息。</p><p>选举机制；当从节点发现自己的主节点挂掉后就会尝试failover成为主节点，他会通过广播的形式发一个syn，只有其他主节点收到后才会回应一个ack，只能回一次，从节点会收集回复自己的ack超过半数以上就会成为新的主节点，当然极端情况如果三个主节点挂了一个，剩下两个主节点分别回复这两个从节点，收到回复ack数量一样，就会重新选举</p><p>脑裂问题：如果没有过半机制的话，可能由于网络抖动哨兵不能感知到主节点，会新选举一个主节点，当原主节点恢复后会成为新的从节点把原来数据清楚，同步现在新主节点的数据，这样就会导致数据丢失<br>可以用redlock利用过半机制解决该问题，但是会牺牲性能</p><h5 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h5><p>实现分布式锁要具备以下几点特性<br>容错<br>复制<br>不能产生死锁<br>不能解锁别人的<br>1、不能产生死锁(使用setIfAbsent将值设置为当前时间加过期时间，设置过期时间，如果已经过期的锁，可以获取锁，但是考虑到并发问题，使用getandset，获取set之前的老值，将当前key的值设置进去，加一个判断，如果老值跟刚才获取的值一致说明没有被修改过，可以加锁(类似cas操作)<br>2、自己加的锁只能自己解锁(解锁的时候判断传入的value是否为当前key的值)<br>3、复制就是用一个value<br>4、容错是集群方面的，只要大部分 Redis 节点启动，客户端可以获取和释放锁</p><p>这样只能实现一个比较高效的分布式锁，还是解决不了解锁原子性的问题，如果解锁的时候我刚执行到比较的位置redis挂了，那这个锁相当于一直没被解开，所以可以使用lua脚本保证原子性。lua脚本适合小批量的执行比较快的命令放在一起执行，因为如果整个lua脚本执行的时间比较长会造成阻塞。</p><p>还有一个问题就是如何设置过期时间问题，如果设置的比较短，当锁已经过期了但是任务还没有执行完成，那么这个锁是可以被其他线程拿到的，要解决这个问题需要实现对锁续命，保证该任务执行完成释放锁，其他线程才能拿到锁，可以使用时间定时线程池或者timer开启一个守护线程，定时去对当前主线程锁重新设置过期时间，但是这样实现起来比较复杂<br>可以利用redison来实现该功能，因为redison底层实现了现成的锁续命，以及使用了大量的lua来保证原子性</p><h5 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h5><p>穿透</p><p>不存在的key<br>1、将不存在的key缓存，设置一个过期时间<br>2.使用布隆过滤器</p><p>击穿</p><p>并发的查同一条过期key<br>1、设置这个热点缓存永不过期。这时要注意在value当中包含一个逻辑<br>上的过期时间，然后另起一个线程，定期重建这些缓存。<br>2、加载DB的时候，要防止并发。</p><p>雪崩</p><p>缓存层支撑不住或者宕机，类似大量请求访问bigkey，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。<br>1、批量更新可以的时候可以随机设置过期时间<br>2、设置热点数据永远不过期<br>3、使用redis集群，将热点数据均匀分布在不同搞得缓存数据库中</p><p>数据不一致</p><p>对于并发量很小的场景几乎可以不考虑该问题，因为发生的概率很小，就算并发量很高，如果是可以容忍短时间数据不一致，可以通过缓存加过期时间解决大部分问题<br>当然如果是读多写少的情况有下面两种方式解决<br>加读写锁，读读不互斥，读写互斥<br>1》先操作缓存，但是不删除缓存。将缓存修改为一个特殊值(-999)。客<br>户端读缓存时，发现是默认值，就休眠一小会，再去查一次Redis。 -》 特殊值对业<br>务有侵入。 休眠时间，可能会多次重复，对性能有影响。<br>2》延时双删。 先删除缓存，然后再写数据库，休眠一小会，再次删除缓存。-》 如<br>果数据写操作很频繁，同样还是会有脏数据的问题。</p><p>清除策略</p><p>被动清理</p><p>.volatile-ttl</p><p>主动清理</p><p>volatile-random</p><p>volatile-lru</p><p>volatile-lfu</p><p>allkeys-random</p><p>allkeys-lru</p><p>淘汰很久没被访问过的数据，以最近一次访问时间作为参考</p><p>allkeys-lfu</p><p>淘汰最近一段时间被访问次数最少的数据，以次数作为参考。</p><p>noeviction</p><p>当内存满了之后触发主动清理</p><p>布隆过滤器</p><p>在布隆过滤器中，如果他说没有的数据那一定没有，如果他说有的数据有可能没有，他存在一定的误判率，使用时需要在启动项目的时候将数据一次性初始化到过滤器中，如果中间有删除更新新增的数据，只能通过定期初始化过滤器来实现，他本身不能更新。<br>原理：他的底层是通过0 1 0 1  这样的二进制位数组来存储某个值是否存证，通过他的几个hash函数判断某个key落到哪个位置，如果存在就设置为1，获取的时候一样通过几个hash函数去定位在那些位置，如果有一个为0就返回不存在，如果都为1极有可能存在，因为有可能这个1是其他key导致的</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>svn报错sqllite database disk image is malformed 的解决方法</title>
    <link href="/2021/06/30/svn%E6%8A%A5%E9%94%99sqllite%20database%20disk%20image%20is%20malformed%20%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <url>/2021/06/30/svn%E6%8A%A5%E9%94%99sqllite%20database%20disk%20image%20is%20malformed%20%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>​                        </p><p>在使用svn的时候可能会出现莫名的报错，比如这个可能是一些异常终止造成的。</p><p>其实解决这个问题也很简单，网上也有很多解决方法，比如重新checkout新的代码即可，但是这样会造成本地未提交代码丢失</p><p>还有安装sqlit3，执行一些命令，寻找问题原因，但是这样会比较费时，如果比较着急使用就不太合适</p><p>所以这里记录一下另外一种简单的方式</p><p>可以新拉一个项目(每个项目根目录都有一个.svn文件夹，这里可能是隐藏了 找不到 可以使用搜索方式进行搜索.svn 获取取消隐藏)</p><p>在项目根目录下找到以下文件将新代码中的文件替换到老项目中</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622153118219.png" alt="image-20210622153118219"></p><p>然后再勾选红框中的对勾 重启idea后再取消红框中的对勾 即恢复提交</p><p>![]<a href="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622160552195.png">https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622160552195.png</a></p><p>另外由于一些误操作有时也可能会报该文件夹中缺少某些文件，同样用正常的该文件夹进行覆盖即可解决 </p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622153714600.png" alt="image-20210622153714600"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo+github快速搭建自己的博客</title>
    <link href="/2021/06/22/hexo+github%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
    <url>/2021/06/22/hexo+github%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p>打开本地git bash 创建一个自己保存博客的文件夹执行以下命令安装hexo</p><p>![image-20210622140851007](<a href="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622140851007.png">https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622140851007.png</a></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622141400643.png" alt="image-20210622141400643"></p><p>hexo详细使用可以在官方文档中查看</p><p><a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a></p><p>安装完成后就可以直接启动hexo</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622141556787.png" alt="image-20210622141556787"></p><p>然后就可以在浏览器上面输入localhost:4000/进入自己本地博客系统</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622141708347.png" alt="image-20210622141708347"></p><p>但是此时只能在本地访问，想要放在公网上就要依赖github了</p><p>先在github上面创建一个项目</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622142416918.png" alt="image-20210622142416918"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622142542793.png" alt="image-20210622142542793"></p><p>然后将hexo和创建的项目绑定在一起。</p><p>这里需要先添加一个秘钥，如果不添加的话，后续每次部署都需要登录两次github会比较麻烦</p><p>依次执行以下命令，(用户名是自己的github账号，邮箱可以随意填写)</p><p>git config –global user.name “WangyihaoJava”</p><p>git config –global user.email “<a href="mailto:WangyihaoJava@qq.com">WangyihaoJava@qq.com</a>“</p><p>ssh-keygen -t rsa</p><p> cd ~/.ssh/</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622143015743.png" alt="img"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622143321190.png" alt="image-20210622143321190"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622143350864.png" alt="image-20210622143350864"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622143442711.png" alt="image-20210622143442711"></p><p>执行完成后可得到一个公钥和私钥，复制公钥在github设置选项配置公钥</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622143930633.png" alt="image-20210622143930633"></p><p>回到gitbash设置配置文件</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622144058941.png" alt="image-20210622144058941"></p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622144218249.png" alt="image-20210622144218249"></p><p>repo就是自己项目的SSH地址</p><p>配置完成就可以新添加一个文件进行测试</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622144429525.png" alt="image-20210622144429525"></p><p>执行命令hexo g -d 将文件部署在github</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622144527496.png" alt="image-20210622144527496"></p><p>访问刚刚创建项目时填写的项目名称</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622144838112.png" alt="image-20210622144838112"></p><p>此时就可以通过该域名访问到自己的博客系统</p><p>但是目前写的博客里面只能是文字，不能使用图片，因为Typora上面的图片是引用本地的</p><p>所以这里需要将图片保存到gitee中，每次有新图片利用picgo自动上传到gitee中</p><p>首先在gitee上面新建一个开源项目保存图片</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622150137663.png" alt="image-20210622150137663"></p><p>生成一个令牌备用</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622150315620.png" alt="image-20210622150315620"></p><p>在Typora中下载picgo</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622145544794.png" alt="image-20210622145544794"></p><p>下载完成安装后在插件设置下载以下插件，只需要下载这一个即可</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622145625907.png" alt="image-20210622145625907"></p><p>repo就是在gitee中保存图片的项目</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622145812308.png" alt="image-20210622145812308"></p><p>repo就是刚刚在gitee中创建的项目，可以直接在url中获取，token就是刚刚生成的令牌，path就是储存图片的位置，branch默认使用master，customPath使用年月</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622150515545.png" alt="image-20210622150515545"></p><p>配置完成之后就可以typora中测试一下</p><p><img src="https://gitee.com/wangyihaogit/blog_imag/raw/master/imag/image-20210622150756407.png" alt="image-20210622150756407"></p><p>成功之后每次在typora中增加图片就会自动上传到gitee中</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/06/20/hello-world/"/>
    <url>/2021/06/20/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
